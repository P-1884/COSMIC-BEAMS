{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "import sys\n",
    "sys.path.append('/mnt/users/hollowayp/paltas')\n",
    "from KDE_one_stop import drop_extra_columns,hyperparam_range_dict,one_stop_kde\n",
    "from Save_Summary_Batches import summary_batch\n",
    "from squash_walkers import squash_walkers\n",
    "from load_h5_file import load_h5_file\n",
    "import matplotlib.pyplot as pl\n",
    "from KDEpy import TreeKDE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import corner\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/extraspace/hollowayp/zBEAMS_data/class_instances/python3.11-Fiducial_0_0-63921.out_5_10_pickle.pkl','rb') as f:\n",
    "    summary_batch_fiducial = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import distributions\n",
    "\n",
    "def ks_weighted(data1, data2, wei1, wei2, alternative='two-sided'):\n",
    "    ix1 = np.argsort(data1)\n",
    "    ix2 = np.argsort(data2)\n",
    "    data1 = data1[ix1]\n",
    "    data2 = data2[ix2]\n",
    "    wei1 = wei1[ix1]\n",
    "    wei2 = wei2[ix2]\n",
    "    data = np.concatenate([data1, data2])\n",
    "    cwei1 = np.hstack([0, np.cumsum(wei1)/sum(wei1)])\n",
    "    cwei2 = np.hstack([0, np.cumsum(wei2)/sum(wei2)])\n",
    "    cdf1we = cwei1[np.searchsorted(data1, data, side='right')]\n",
    "    cdf2we = cwei2[np.searchsorted(data2, data, side='right')]\n",
    "    d = np.max(np.abs(cdf1we - cdf2we))\n",
    "    # calculate p-value\n",
    "    n1 = data1.shape[0]\n",
    "    n2 = data2.shape[0]\n",
    "    m, n = sorted([float(n1), float(n2)], reverse=True)\n",
    "    en = m * n / (m + n)\n",
    "    if alternative == 'two-sided':\n",
    "        prob = distributions.kstwo.sf(d, np.round(en))\n",
    "    else:\n",
    "        z = np.sqrt(en) * d\n",
    "        # Use Hodges' suggested approximation Eqn 5.3\n",
    "        # Requires m to be the larger of (n1, n2)\n",
    "        expt = -2 * z**2 - 2 * z * (m + 2*n)/np.sqrt(m*n*(m+n))/3.0\n",
    "        prob = np.exp(expt)\n",
    "    return d, prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = np.random.normal(0,1,1000)\n",
    "d2 = np.random.normal(0,1,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JAX_chains_list_hyp = []\n",
    "for chain_i in tqdm(range(len(summary_batch_fiducial.JAX_chains_list))):\n",
    "    JAX_chains_list_hyp.append(squash_walkers(drop_extra_columns(summary_batch_fiducial.JAX_chains_list[chain_i].loc[:1999],\n",
    "                                          Ok=True,alpha_weights_2=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_dict = {}\n",
    "for chain in range(len(JAX_chains_list_hyp)):\n",
    "    kde_dict[chain] = KernelDensity(bandwidth=0.01).fit(JAX_chains_list_hyp[chain]['OM'].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_dict = {'bins':np.linspace(-0.1,1.1,121),'alpha':0.5,'density':True}\n",
    "# pl.hist(kde_dict[0].sample(len(JAX_chains_list_hyp[0]['OM'])).flatten(),**hist_dict)\n",
    "X_plot = np.linspace(-0.1,1.1,100)\n",
    "pl.hist(JAX_chains_list_hyp[0]['OM'],**hist_dict)\n",
    "pl.plot(X_plot,np.exp(kde_dict[0].score_samples(X_plot.reshape(-1,1))),c='k')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_n_PCA(data):\n",
    "    var_perc = 0.95\n",
    "    pca_test = PCA(n_components=len(data.columns))  # Reduce to 10 dimensions (adjust based on data)\n",
    "    pca_test_fit = pca_test.fit_transform(data)\n",
    "    pca_variance = pca_test.explained_variance_ratio_/np.sum(pca_test.explained_variance_ratio_)\n",
    "    n_PCA = np.arange(len(data.columns))[np.where(np.cumsum(pca_variance)>var_perc)[0]][0]\n",
    "    print(f'Using {n_PCA} PCA components, which explain {var_perc}% of the variance')\n",
    "    return n_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class KDE_scaling:\n",
    "    def __init__(self,JAX_chains_list_hyp,N_dim,N_sys,N_iterations,bandwidth=0.05,shuffle_params=True,PCA_bool=False):\n",
    "        np.random.seed(1)\n",
    "        self.JAX_chains_list_hyp = copy.deepcopy(JAX_chains_list_hyp)\n",
    "        self.bandwidth = bandwidth\n",
    "        self.PCA_bool = PCA_bool\n",
    "        del JAX_chains_list_hyp\n",
    "        #Rescaling to std = 1:\n",
    "        self.OM_std = np.mean([np.std(self.JAX_chains_list_hyp[elem]['OM']) for elem in range(len(self.JAX_chains_list_hyp))])\n",
    "        self.std_array = np.mean([self.JAX_chains_list_hyp[elem].describe().loc['std'].to_numpy() for elem in range(len(self.JAX_chains_list_hyp))],axis=0)\n",
    "        # print('Std',self.std_array)\n",
    "        for b_i in range(len(self.JAX_chains_list_hyp)):\n",
    "            self.JAX_chains_list_hyp[b_i]/=self.std_array\n",
    "        # print('Describe',self.JAX_chains_list_hyp[0].describe())\n",
    "        # print('Describe, unscaled',JAX_chains_list_hyp[0].describe())\n",
    "        self.N_dim = N_dim\n",
    "        #NOT including OM as this is included seperately later:\n",
    "        self.param_list = ['Ode','w','wa']+\\\n",
    "                ['alpha_mu_0','alpha_mu_1','alpha_mu_2','alpha_weights_0','alpha_weights_1','alpha_scale_0','alpha_scale_1','alpha_scale_2']+\\\n",
    "                ['s_c','s_m','scale_c','scale_m']\n",
    "        self.param_list_dict = {}\n",
    "        self.N_sys = N_sys\n",
    "        self.N_iterations = N_iterations\n",
    "        self.kde_dict = {elem:[] for elem in range(len(self.JAX_chains_list_hyp))}\n",
    "        self.indx_dict = {elem:[] for elem in range(len(self.JAX_chains_list_hyp))}\n",
    "        self.JAX_chains_list_iterations = {elem:[] for elem in range(len(self.JAX_chains_list_hyp))}\n",
    "        self.PCA_func = []\n",
    "        self.PCA_transform = {elem:[] for elem in range(len(self.JAX_chains_list_hyp))}\n",
    "        self.n_PCA_dict = {}\n",
    "        for iteration_i in range(N_iterations):\n",
    "            if shuffle_params: self.param_list_dict[iteration_i] = ['OM']+np.random.choice(self.param_list,N_dim-1,replace=False).tolist()\n",
    "            else: self.param_list_dict[iteration_i] = ['OM']+self.param_list[:N_dim-1]\n",
    "            self.n_PCA_dict[iteration_i] = calculate_n_PCA(self.JAX_chains_list_hyp[0][self.param_list_dict[iteration_i]])\n",
    "            for chain in range(len(self.JAX_chains_list_hyp)):\n",
    "                random_indx = np.random.choice(np.arange(len(self.JAX_chains_list_hyp[chain])),N_sys,replace=False)\n",
    "                self.indx_dict[chain].append(random_indx)\n",
    "                self.JAX_chains_list_iterations[chain].append(self.JAX_chains_list_hyp[chain].loc[random_indx])\n",
    "                if PCA_bool:\n",
    "                    if chain==0: self.PCA_func.append(PCA(n_components=self.n_PCA_dict[iteration_i],whiten=True))\n",
    "                    if chain==0: self.PCA_transform[chain].append(self.PCA_func[iteration_i].fit_transform(self.JAX_chains_list_iterations[chain][iteration_i][self.param_list_dict[iteration_i]].to_numpy()))\n",
    "                    else: self.PCA_transform[chain].append(self.PCA_func[iteration_i].transform(self.JAX_chains_list_iterations[chain][iteration_i][self.param_list_dict[iteration_i]].to_numpy()))\n",
    "        for iteration_i in range(N_iterations):\n",
    "            for chain in range(len(self.JAX_chains_list_hyp)):\n",
    "                if PCA_bool: \n",
    "                    kde_input_data = self.PCA_transform[chain][iteration_i]\n",
    "                    if self.n_PCA_dict[iteration_i]==1: kde_input_data = kde_input_data.reshape(-1,1)\n",
    "                    # print('KDE input',kde_input_data.shape,np.std(kde_input_data,axis=0))\n",
    "                else: \n",
    "                    kde_input_data = self.JAX_chains_list_iterations[chain][iteration_i][self.param_list_dict[iteration_i]].to_numpy()\n",
    "                    if self.N_dim==1: kde_input_data = kde_input_data.reshape(-1,1)\n",
    "                self.kde_dict[chain].append(KernelDensity(bandwidth=bandwidth).fit(kde_input_data))\n",
    "        # print('Param list:',self.param_list_dict)\n",
    "    def find_product(self):\n",
    "        assert len(self.JAX_chains_list_hyp)==2 #Am only finding the product with the 2nd index.\n",
    "        self.prod_dict = {elem:[] for elem in range(len(self.JAX_chains_list_hyp))}\n",
    "        for iteration_i in range(self.N_iterations):\n",
    "            for chain in range(len(self.JAX_chains_list_hyp)):\n",
    "                if self.PCA_bool:\n",
    "                    if self.N_dim==1: prod_i = np.exp(self.kde_dict[chain][iteration_i].score_samples(self.PCA_func[iteration_i].transform(self.JAX_chains_list_hyp[1-chain][self.param_list_dict[iteration_i]].to_numpy()).reshape(-1,1)))\n",
    "                    else: prod_i = np.exp(self.kde_dict[chain][iteration_i].score_samples(self.PCA_func[iteration_i].transform(self.JAX_chains_list_hyp[1-chain][self.param_list_dict[iteration_i]].to_numpy())))\n",
    "                    # print('Prod shape',prod_i.shape)\n",
    "                else:\n",
    "                    if self.N_dim==1: prod_i = np.exp(self.kde_dict[chain][iteration_i].score_samples(self.JAX_chains_list_hyp[1-chain][self.param_list_dict[iteration_i]].to_numpy().reshape(-1,1)))\n",
    "                    else: prod_i = np.exp(self.kde_dict[chain][iteration_i].score_samples(self.JAX_chains_list_hyp[1-chain][self.param_list_dict[iteration_i]].to_numpy()))\n",
    "                self.prod_dict[chain].append(prod_i)\n",
    "        return self\n",
    "    def compare_1D_histogram(self,plot=False):\n",
    "        try: self.prod_dict\n",
    "        except: self.find_product()\n",
    "        hist_dict_2 = {'bins':np.linspace(0,1,51),'density':True}\n",
    "        plot_hist_dict_2 = {'bins':np.linspace(-0.1,1.1,51),'density':True,'fill':False,'linewidth':2}\n",
    "        ratio_list = []\n",
    "        for iteration_i in range(self.N_iterations):\n",
    "            for chain_i in range(1):#range(len(self.JAX_chains_list_hyp)): #Degenerate with 1-chain.\n",
    "                #Applying the std back to the OM:\n",
    "                w1 = self.prod_dict[1-chain_i][iteration_i]\n",
    "                w2 = self.prod_dict[chain_i][iteration_i]\n",
    "                # print('weights',self.JAX_chains_list_hyp[chain_i]['OM'].shape,w1.shape)\n",
    "                f1,b1 = np.histogram(self.JAX_chains_list_hyp[chain_i]['OM']*self.OM_std,weights=w1,**hist_dict_2)\n",
    "                f2,b2 = np.histogram(self.JAX_chains_list_hyp[1-chain_i]['OM']*self.OM_std,weights=w2,**hist_dict_2)\n",
    "                ratio_list.append(np.nanmedian(abs(f1-f2)/f2))\n",
    "                if plot:\n",
    "                    print('Iteration',iteration_i,'Params',self.param_list_dict[iteration_i])\n",
    "                    if self.PCA_bool: fig,ax = pl.subplots(figsize=(7,5));ax_0=ax\n",
    "                    else:fig,ax = pl.subplots(1,2,figsize=(10,5));ax_0=ax[0];ax_1=ax[1]\n",
    "                    ax_0.hist(self.JAX_chains_list_hyp[chain_i]['OM']*self.OM_std,weights=self.prod_dict[1-chain_i][iteration_i],\n",
    "                            **plot_hist_dict_2,edgecolor='darkorange')\n",
    "                    ax_0.hist(self.JAX_chains_list_hyp[1-chain_i]['OM']*self.OM_std,weights=self.prod_dict[chain_i][iteration_i],\n",
    "                            **plot_hist_dict_2,edgecolor='darkblue')\n",
    "                    ax_0.set_xlabel('OM')\n",
    "                    ax_0.set_title(f'Product of KDEs in {self.N_dim}D: Bandwidth: {self.bandwidth}')\n",
    "                    KDE_1D = KernelDensity(bandwidth=self.bandwidth).fit(self.JAX_chains_list_hyp[chain]['OM'].loc[self.indx_dict[chain][iteration_i]].to_numpy().reshape(-1,1))\n",
    "                    if not self.PCA_bool:\n",
    "                        ax_1.hist(self.JAX_chains_list_hyp[chain_i]['OM']*self.OM_std,\n",
    "                            **plot_hist_dict_2,edgecolor='grey',alpha=0.5)\n",
    "                        ax_1.hist(self.JAX_chains_list_hyp[1-chain_i]['OM']*self.OM_std,\n",
    "                            **plot_hist_dict_2,edgecolor='grey',alpha=0.5)\n",
    "                        ax_1.set_xlabel('OM')\n",
    "                        ax_1.set_title(f'KDE in 1D: Bandwidth: {self.bandwidth}')\n",
    "                        X_plot = np.linspace(-0.1,1.1,100)\n",
    "                        ax_1.plot(X_plot,np.exp(KDE_1D.score_samples(X_plot.reshape(-1,1)/self.OM_std))/self.OM_std,c='k')                    \n",
    "                    if plot: pl.show()\n",
    "        self.ratio_list = ratio_list\n",
    "        return self\n",
    "\n",
    "mean_ratio = {}\n",
    "mean_ratio_std = {}\n",
    "N_sys_list = [1000,5000,10000,15000]\n",
    "N_dim_list = np.arange(3,8)\n",
    "N_dim_max = np.max(N_dim_list)\n",
    "N_iterations=3\n",
    "bandwidth_list = [0.01,0.05,0.1,0.2]\n",
    "for bandwidth in bandwidth_list:\n",
    "    for N_dim in N_dim_list:\n",
    "        mean_ratio[(N_dim,bandwidth)] = []\n",
    "        mean_ratio_std[(N_dim,bandwidth)] = []\n",
    "        for N_sys in tqdm(N_sys_list):\n",
    "            ratio_list_i = KDE_scaling(JAX_chains_list_hyp,N_dim=N_dim,\n",
    "                                       N_sys=N_sys,N_iterations=N_iterations,\n",
    "                                       bandwidth=bandwidth,PCA_bool=True).compare_1D_histogram(plot=False).ratio_list\n",
    "            print(f'Ratio list: {ratio_list_i}')\n",
    "            mean_ratio[(N_dim,bandwidth)].append(np.nanmean(ratio_list_i))\n",
    "            mean_ratio_std[(N_dim,bandwidth)].append(np.nanstd(ratio_list_i))\n",
    "            plot_scaling_relation(N_dim,N_sys_list,mean_ratio,mean_ratio_std,\n",
    "                                  bandwidth_list=bandwidth_list,N_dim_max=N_dim_max,\n",
    "                                saveas='/mnt/zfsusers/hollowayp/zBEAMS/KDE_scaling_relation_plot_test'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = pl.subplots(1,len(JAX_chains_list_hyp),figsize=(5*len(JAX_chains_list_hyp),5))\n",
    "for b_i in range(len(JAX_chains_list_hyp)):\n",
    "    ax[b_i].hist(JAX_chains_list_hyp[b_i]['OM'],bins=np.linspace(0,1,51),density=True,alpha=0.5)\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_dataset = [pd.concat([JAX_chains_list_hyp[0],JAX_chains_list_hyp[1]]).reset_index(drop=True),\n",
    "                pd.concat([JAX_chains_list_hyp[2],JAX_chains_list_hyp[3]]).reset_index(drop=True)]\n",
    "KDE_large = KDE_scaling(large_dataset,N_dim=16,\n",
    "            N_sys=len(large_dataset[0]),N_iterations=1,\n",
    "            bandwidth=0.2,PCA_bool=True).compare_1D_histogram(plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KDE_scaling(JAX_chains_list_hyp,N_dim=N_dim,\n",
    "                    N_sys=N_sys,N_iterations=N_iterations,bandwidth=bandwidth).compare_1D_histogram(plot=(N_dim>4)).ratio_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scaling_relation(N_dim,N_sys_list,mean_ratio,mean_ratio_std,\n",
    "                                  bandwidth_list=bandwidth_list,N_dim_max=N_dim_max,\n",
    "                                saveas='/mnt/zfsusers/hollowayp/zBEAMS/test_figure_can_delete'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=16)  # Reduce to 10 dimensions (adjust based on data)\n",
    "X_f_reduced = pca.fit_transform(JAX_chains_list_hyp[0])\n",
    "print(np.arange(16)[np.where(np.cumsum(pca.explained_variance_ratio_/np.sum(pca.explained_variance_ratio_))>0.99)[0]])\n",
    "print(np.cumsum(pca.explained_variance_/np.sum(pca.explained_variance_)))\n",
    "pl.plot(pca.explained_variance_/np.sum(pca.explained_variance_))\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scaling_relation(N_dim,N_sys_list,mean_ratio,mean_ratio_std,bandwidth_list,N_dim_max=3,saveas=None):\n",
    "    fig = pl.figure(figsize=(7,5))\n",
    "    pl.title('KDE Scaling',size=18)\n",
    "    linestyle_list = ['-','--',':','-.','--',':','-.']\n",
    "    color_dict = {elem+1:pl.cm.viridis(np.linspace(0,1,N_dim_max))[elem] for elem in range(N_dim_max)}\n",
    "    for p_i,key_i in enumerate(mean_ratio_std.keys()):\n",
    "        N_dim,bandwidth = key_i\n",
    "        linestyle_i = linestyle_list[np.where(np.array(bandwidth_list)==bandwidth)[0][0]]\n",
    "        pl.errorbar(N_sys_list[:len(mean_ratio[(N_dim,bandwidth)])],mean_ratio[(N_dim,bandwidth)],\n",
    "                        yerr=mean_ratio_std[(N_dim,bandwidth)],\n",
    "                        linestyle=linestyle_i,\n",
    "                    c=color_dict[N_dim],label=f'{N_dim}D,B:{bandwidth}')\n",
    "    pl.xlabel('Number of systems',size=15)\n",
    "    pl.ylabel('Median bin ratio',size=15)\n",
    "    fig.legend(fontsize=7,bbox_to_anchor=(1.12,0.5),loc='center right')\n",
    "    pl.ylim(-0.1,2.1)\n",
    "    pl.tight_layout()\n",
    "    if saveas is not None:\n",
    "        for fmt in ['pdf','png']: pl.savefig(saveas+f'.{fmt}',dpi=500,bbox_inches='tight')\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = np.linspace(-2,2,100)\n",
    "Y_1D = np.exp(KernelDensity().fit([[0]]).score_samples(X_plot.reshape(-1,1)))\n",
    "Y_2D = np.exp(KernelDensity().fit([[0,0]]).score_samples(np.array([X_plot,np.zeros(len(X_plot))]).T))\n",
    "\n",
    "pl.plot(X_plot,Y_1D/np.max(Y_1D),label='1D')\n",
    "pl.plot(X_plot,Y_2D/np.max(Y_2D),'--',label='2D')\n",
    "pl.ylim(bottom=0)\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vs_code_python114_archive_zBEAMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
